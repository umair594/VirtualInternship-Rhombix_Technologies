{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umair594/VirtualInternship-Rhombix_Technologies/blob/main/Leaf_Disease_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Leaf Disease Detection Using Deep Learning**"
      ],
      "metadata": {
        "id": "jYZMn-sHvFLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our \"Leaf Disease Detection Using Deep Learning\" project uses advanced CNN models to spot plant diseases directly from leaf images. This tool helps farmers catch issues early, reducing crop losses and boosting yields. With image enhancements and data augmentation, we’ve achieved high accuracy, making it a reliable solution for healthier crops and a great example of deep learning’s potential in agriculture."
      ],
      "metadata": {
        "id": "nxyzsuXavLHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Overview**"
      ],
      "metadata": {
        "id": "N-Soo9_SvO0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to the \"Leaf Disease Detection Using Deep Learning\" project. This impressive project addresses the problem of diagnosing and categorizing leaf disease using deep learning methods.\n",
        "\n",
        "From the perspective of recognition simplicity, this project really enhances the process of early detection for farmers who want to protect their crops or garden lovers who want to know how healthy their plants are. Thus, based on convolutional neural network (CNN) models such as VGG16, VGG19, and EfficientNet-B4, we simultaneously achieved high diagnostic accuracy of diseases from different plant species, ensuring correct identification of diseases and minimizing crop losses to improve yield."
      ],
      "metadata": {
        "id": "XzzfR_S-vTef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prerequisites**"
      ],
      "metadata": {
        "id": "Lhq2rRxZvcUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before trying your hand at this particular project, you must have the following:\n",
        "Python programming proficiency (from basic to intermediate level).\n",
        "\n",
        "Understanding of the core principles of Machine Learning and Deep Learning.\n",
        "\n",
        "Experience with TensorFlow and Keras for building and developing models.\n",
        "\n",
        "Competence in Google Colab to execute the code and retrieve the datasets.\n",
        "\n",
        "Basic knowledge of image processing and convolutional neural networks (CNNs).\n",
        "\n"
      ],
      "metadata": {
        "id": "Ej7BsFoGvhMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Approach**"
      ],
      "metadata": {
        "id": "q7ZD7uyqvoKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project approach is to use transfer learning techniques to detect leaf disease from images. We used three pre-trained models. Which are Vgg-16, Vgg-19 and Efficient-B4. Our models are trained with thousands of images of diseased leaves and healthy leaves. Which ultimately learns to distinguish between different categories with impressive accuracy.\n",
        "\n",
        "\n",
        "The ultimate objective is to make disease diagnosis easy and alleviate the burden of plant diseases through the use of artificial intelligence."
      ],
      "metadata": {
        "id": "A1ue7H5ovtwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Workflow and Methodology details**"
      ],
      "metadata": {
        "id": "k2-0JVUFvyZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The broad overview of this project is as follows:\n",
        "Data Collection: First, we gathered the datasets made of the images of healthy and infected leaf samples.\n",
        "\n",
        "Data preprocessing: Once we gathered samples, the images were normalized and then divided into data for training and others for validation.\n",
        "\n",
        "Model Building: Implementing transfer learning using the pre-trained models of VGG16, VGG19 and EfficientNet-b4\n",
        "\n",
        "Training the Model: subsequently, models are then developed on training databases in a manner to efficiently diagnose leaf disease.\n",
        "\n",
        "Evaluation: Carrying out model testing and its performance assessment."
      ],
      "metadata": {
        "id": "VHVwVsQjv4Z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The methodology includes:**"
      ],
      "metadata": {
        "id": "wrSrEShCwBpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNNs for Feature Extraction: Implementing Convolution Layers for the Important Features on the Images.\n",
        "\n",
        "Transfer Learning: Implementation of pre-trained models (VGG16, VGG19, Efficient-b4) that reduce the time for learning the target model.\n",
        "\n",
        "Data Augmentation: Enhancement of the model performance via augmentation methods over the dataset."
      ],
      "metadata": {
        "id": "pbji6HHCwF2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collection**"
      ],
      "metadata": {
        "id": "oWj2L5WdwIob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this research, the dataset was collected from the Kaggle platform, which included pictures of healthy as well as infected leaves. During the analysis of images, it was clear that there were classes with a lot fewer images than the rest, resulting in an unequal dataset.\n",
        "\n",
        "\n",
        "We have a dataset that comprises 8320 training pictures and 2080 validation images. They are divided into 26 classes of plant leaves disease and healthy leaves. These pictures were divided according to the different crops, such as apples, corn, grapes, etc."
      ],
      "metadata": {
        "id": "XAVXxtk3wM_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preparation**"
      ],
      "metadata": {
        "id": "K2Z1H7-mwRdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our case, after labeling the dataset, images are resized to 128x128 pixels for easy fitting. OpenCV and TensorFlow allow images to be processed by:\n",
        "\n",
        "Resizing and normalizing pixel values.\n",
        "\n",
        "Label the images according to the respective class (disease or healthy).\n",
        "\n",
        "Augmentation techniques like flipping, rotating, and zooming to balance the dataset.\n",
        "\n",
        "Normalize the pixel values to speed up model training."
      ],
      "metadata": {
        "id": "rSK2s_jvwVVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation Workflow**"
      ],
      "metadata": {
        "id": "HRssiSK4wYyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load images and corresponding labels.\n",
        "\n",
        "Resize images to 128x128.\n",
        "\n",
        "Normalize the pixels.\n",
        "\n",
        "Divide the available data into training and validation data."
      ],
      "metadata": {
        "id": "SxugQg4swcyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code Explanation**"
      ],
      "metadata": {
        "id": "x46zapPTwfs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's what is happening under the hood. Let's go through it step by step:"
      ],
      "metadata": {
        "id": "iDqm642AwnbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1:**\n",
        "Mounting Google Drive\n",
        "Mount your Google Drive to access and save datasets, models, and other resources."
      ],
      "metadata": {
        "id": "ScXa1XfnxK8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7HQHFssvKX_",
        "outputId": "56fba8c2-70ac-4d7f-b154-b8f8b2746d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Package installation**\n",
        "\n",
        "Installs the TensorFlow packages for building and training machine learning and deep learning models."
      ],
      "metadata": {
        "id": "ibFv2bWeyDUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPJ9kg6dyJN_",
        "outputId": "45b19ad6-491a-47d6-b261-c38afe921f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**\n",
        "\n",
        "Libraries like os, PIL, OpenCV, Matplotlib, and NumPy are imported for interacting with the file system, managing image input/output, processing, and visualization. Keras and TensorFlow are well-known libraries for constructing neural networks. Various layers, models, and utilities are employed to define, compile, and train deep learning models."
      ],
      "metadata": {
        "id": "TL2sj3uWzGT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image,ImageOps\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, ReLU, ELU, Dropout, Conv2D, Dense, MaxPool2D, AvgPool2D, GlobalAvgPool2D, Concatenate\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model, model_from_json, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, SeparableConv2D, UpSampling2D, BatchNormalization, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "mMdJAZOSzL12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading and Preprocessing**\n",
        "\n",
        "This section specifies the location of the dataset folders. The dataset is divided into two parts: training and validation. All images are resized to a standard dimension of 128x128 pixels to ensure uniformity throughout the dataset."
      ],
      "metadata": {
        "id": "gfJr7CHmzRA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='/content/drive/MyDrive/Rhombix_Technologies_Internship/Leaf Disease Detection_Task_03'\n",
        "train_folder = os.path.join(dataset,\"training\")\n",
        "test_folder = os.path.join(dataset,\"validation\")"
      ],
      "metadata": {
        "id": "ctS50wPSzVUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extract categories**"
      ],
      "metadata": {
        "id": "WIxP09Wh2r-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 128\n",
        "categories = []\n",
        "for i in os.listdir(train_folder):\n",
        "  categories.append(i)\n",
        "  print(categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "5eCr1Q6s2yQy",
        "outputId": "c13bb1a5-96b9-42bb-f84a-441d05ce4878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Rhombix_Technologies_Internship/Leaf Disease Detection_Task_03/training'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2577034048.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Rhombix_Technologies_Internship/Leaf Disease Detection_Task_03/training'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Processing Function**"
      ],
      "metadata": {
        "id": "yOUPcfiM5gh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Process Data\n",
        "def process_data(folder, categories, img_size):\n",
        "  data = []\n",
        "  class_counts = {category : 0 for category in categories}\n",
        "  for c in categories:\n",
        "    path = os.path.join(folder, c)\n",
        "    class_num = categories.index(c)\n",
        "    for img in tqdm(os.listdir(path), desc=f\"Processing {c}\"):\n",
        "      try:\n",
        "        img.array = cv2.imread(os.path.join(path, img))\n",
        "        img.resized = cv2.resize(img_array, (img_size, img_size))\n",
        "        data.append([img_resized, classes_num])\n",
        "        class_counts[c] += 1\n",
        "        except Exception as e:\n",
        "          pass\n",
        "    print(f\"Class '{c}' has {class_counts[c]} images\")\n",
        "    return data, class_counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "hKcPAKax5oQD",
        "outputId": "e9fe720f-bd8f-49e5-f55f-93f05dacaeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-317697629.py, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-317697629.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Process Training Data**"
      ],
      "metadata": {
        "id": "2Pj8FZrQ8rQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Process Training data\n",
        "training_data, train_class_counts = process_data(train_folder, categories, img_size)\n",
        "print(f\"Total training data: {len(training_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "6z28z6oG8vxr",
        "outputId": "c782de7a-c5d9-4678-ae7d-214de96128fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'process_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-842778198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Process Training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_class_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total training data: {len(training_data)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'process_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot Training Data Distribution**"
      ],
      "metadata": {
        "id": "eS37nJul9l2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Class Distribution\n",
        "def plot_class_distribution(class_counts, title):\n",
        "  classes = list(class_counts.keys())\n",
        "  counts = list(class_counts.values())\n",
        "\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.bar(classes, counts, colors='blue')\n",
        "  plt.xlabel('Classes')\n",
        "  plt.ylabel('Number of Images')\n",
        "  plt.title(title)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.show()\n",
        "\n",
        "  plot_class_distribution(class_counts=train_class_counts, title='Training Data Class Distribution')"
      ],
      "metadata": {
        "id": "vSu6wvgj9rLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Process Validation Data**"
      ],
      "metadata": {
        "id": "ikNavfaQYNak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Process Validation Data\n",
        "validatiion_data, val_class_counts = process_data(test_folder, categories, img_size)\n",
        "print(f\"Total validation data: {len(validation_data)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MTGpej0HYVvl",
        "outputId": "76d38b04-c58f-48e0-b0ec-2c3279913e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'process_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-204997100.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Process Validation Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidatiion_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_class_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total validation data: {len(validation_data)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'process_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Class Distribution\n",
        "#Plot Class Distribution\n",
        "def plot_class_distribution(class_counts, title):\n",
        "  classes = list(class_counts.keys())\n",
        "  counts = list(class_counts.values())\n",
        "\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.bar(classes, counts, colors='blue')\n",
        "  plt.xlabel('Classes')\n",
        "  plt.ylabel('Number of Images')\n",
        "  plt.title(title)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.show()\n",
        "\n",
        "  plot_class_distribution(class_counts=train_class_counts, title='Validation Data Class Distribution')"
      ],
      "metadata": {
        "id": "aL_uwZQrZlD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prepare Training Array**"
      ],
      "metadata": {
        "id": "6sk_OBH3Z5xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "for img, label in training_data:\n",
        "  X_train.append(img)\n",
        "  Y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train).astype('float32').reshape(-1, img_size, img_size, 3)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "print(f\"X_train= {X_train.shape} Y_train= {Y_train.shape}\")"
      ],
      "metadata": {
        "id": "viSrdP3JZ_fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation on Validation Dataset**"
      ],
      "metadata": {
        "id": "p3ft1xsQbWgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "for img, label in training_data:\n",
        "  X_train.append(features)\n",
        "  Y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train).astype('float32').reshape(-1, img_size, img_size, 3)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "print(f\"X_train= {X_train.shape} Y_train= {Y_train.shape}\")\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "metadata": {
        "id": "jKqgQQ-PbgPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Show Sample Images**"
      ],
      "metadata": {
        "id": "oKv_3ymXcA7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Function to show one image from each class\n",
        "def show_sample_images(train_folder, categories):\n",
        "  plt.figure(figsize=20. 20)\n",
        "  for i, category in enumerate(categories):\n",
        "    category_path = os.path.join(train_folder, category)\n",
        "    images = os.listdir(category_path)\n",
        "    ramdom_image = random.choice(images)\n",
        "    img_path = os.path.join(category_path, random_image)\n",
        "    img = plt.imread(img_path)\n",
        "\n",
        "    ax = plt.subplot(6, 5, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(category)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "  plt.tight_layout\n",
        "  plt.show()\n",
        "\n",
        "#Call the function to show sample images\n",
        "show_sample_images(train_folder, categories)"
      ],
      "metadata": {
        "id": "NQcYmWr3cOxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a VGG16 Model**"
      ],
      "metadata": {
        "id": "QiSol8KLqoiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (img_size, img_size, 3)\n",
        "num_classes = 26"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "collapsed": true,
        "id": "NPc3nWlkqz3L",
        "outputId": "578f4795-ed78-4c75-c8b1-80eb0801dce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'img_size' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4023208782.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build and Compile Custom VGG16 Model**"
      ],
      "metadata": {
        "id": "lnhhuAwUrA-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "vgg16_custom_model= Sequential()\n",
        "vgg16_custom_model.add(vgg16_model)\n",
        "vgg16_custom_model.add(GlobalAveragePooling2D())\n",
        "vgg16_custom_model.add(Dense(512, activation='relu'))\n",
        "vgg16_custom_model.add(BatchNormalization())\n",
        "vgg16_custom_model.add(Dropout(0.5))\n",
        "vgg16_custom_model.add(Dense(512, activation='relu'))\n",
        "vgg16_custom_model.add(BatchNormalization())\n",
        "vgg16_custom_model.add(Dropout(0.5))\n",
        "vgg16_custom_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "#Compile the model\n",
        "vgg16_custom_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Print the model\n",
        "vgg16_custom_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "VWDfavP0rQkE",
        "outputId": "043f0b3f-5209-486a-f30f-48c1245e4a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input_shape' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1007085015.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvgg16_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvgg16_custom_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the Customized Vgg16 Model**"
      ],
      "metadata": {
        "id": "o0JoUrq_tHxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_pretrained= vgg16_custom_model.fit(\n",
        "    x=X_train,\n",
        "    Y=Y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10\n",
        "    validatoion_data=(X_test, Y_test),\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "oBxtIAzKtgmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting Training & Validation Performance of Vgg16**"
      ],
      "metadata": {
        "id": "ozp0rZ0muF6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, title):\n",
        "  plt.figure(figsize=(10, 5))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(history.history['Accuracy'], label='train accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.title(f'{title} - Accuracy-curves')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(history.history['loss'], label='train loss')\n",
        "  plt.plot(history.history['val_loss'], label='val loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.title(f'{title} - Loss-curves')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  plot_history(history=vgg16_pretrained, title='Vgg16')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1umrZT9augep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating the VGG16 Model Performance**"
      ],
      "metadata": {
        "id": "Cty2Lb5_v5U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss, valid_accuracy = vgg16_custom_model.evaluate(X_test, Y_test)\n",
        "train_loss, train_accuracy = vgg16_custom_model.evaluate(X_train, Y_train)\n",
        "print(f'\\nValidation Accuracy: {valid_accuracy}')\n",
        "print(f'\\nValidation Loss: {valid_loss}')\n",
        "print(f'\\nTraining Accuracy: {train_accuracy}')\n",
        "print(f'\\nTraining Loss: {train_loss}')"
      ],
      "metadata": {
        "id": "Ia-sKbxGwIcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing the Final Accuracy of the VGG16 Model**"
      ],
      "metadata": {
        "id": "MYqg5Gf8xE-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy= vgg16_custom_model.evaluate(X_test, Y_test)\n",
        "print(\"Accuracy: {accuracy * 100:2f}%\")"
      ],
      "metadata": {
        "id": "Yj5QqU0DxcG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizaing Model Predictions with a confusion Matrix**"
      ],
      "metadata": {
        "id": "KFUrEFGcyJl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix=(model, X_test, Y_test, categories, title):\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_test_classes = np.argmix(Y_pred, axis=1)\n",
        "\n",
        "    cm = confusion_matrix(Y_test, Y_test_classes)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "    plot_confusion_matrix(model=vgg16_custom_model, X_test=X_test, Y_test=Y_test, categories=categories, title='Vgg16')"
      ],
      "metadata": {
        "id": "xT6d_ugryWkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating the Classification Report for VGG16 Model**"
      ],
      "metadata": {
        "id": "08venj3UzYU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = vgg16_custom_model.predict(X_test)\n",
        "Y_test_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "#Print Classification report\n",
        "print(classification_report(Y_test, Y_test_classes, target_names=categories))"
      ],
      "metadata": {
        "id": "ZE28yJ-8zqcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building and Compiling a Cuastomized VGG16 Model**"
      ],
      "metadata": {
        "id": "T6EVGlg6z17W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensdorflow.keras.layers import Dense, GlobalAveragerPooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "#Now you can use your VGG19 in your code\n",
        "base_model= VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "#Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable= False\n",
        "\n",
        "#Add custom layers on top in the base model\n",
        "x = base_model_output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#Create a modified VGG19 Model\n",
        "vgg19_custom_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#Compile the model\n",
        "vgg19_custom_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Display the model Summary\n",
        "vgg19_custom_model.summary()"
      ],
      "metadata": {
        "id": "zmD2Brnr0s31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the customized VGG19 Model with Entry Stopping**"
      ],
      "metadata": {
        "id": "V4pekJzy3-gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = modified_vgg19_model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    epochs=10\n",
        "    batch_size=32,\n",
        "    callbacks=[tf.keras.callbacks.Early stopping(patience=5, restore_best_weights=True)]\n",
        ")"
      ],
      "metadata": {
        "id": "CR8cp2ad_T_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the Trained VGG19 Model"
      ],
      "metadata": {
        "id": "66pvfX5cALFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#save the Model\n",
        "vgg19_custom_model.save('/content/drive/MyDrive/new_projects/p5/modified_vgg19_custom_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "collapsed": true,
        "id": "xkSv_HnZAcld",
        "outputId": "48f44e32-eaa8-401e-b747-45a0317f47bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vgg19_custom_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3984902083.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#save the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvgg19_custom_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/new_projects/p5/modified_vgg19_custom_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vgg19_custom_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting Training and Validation Curves for VGG19**"
      ],
      "metadata": {
        "id": "vVGOKPQEA-BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WKDEEDgtBH_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating the Modified VGG19 Model **"
      ],
      "metadata": {
        "id": "_CNK0-XSBsEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss, valid_acc = modified_vgg19_model.evaluate(X_test, Y_test)\n",
        "train_loss, train_acc = modified_vgg19_model.evaluate(X_train, Y_train)\n",
        "print(f'\\nValidation Accuracy: {valid_acc}')\n",
        "print(f'\\nValidation Loss: {valid_loss}')\n",
        "print(f'\\nTraining Accuracy: {train_acc}')\n",
        "print(f'\\nTraining Loss: {train_loss}')"
      ],
      "metadata": {
        "id": "qJylkVW8B0Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing the Final accuracy of the Modified VGG19 Model**"
      ],
      "metadata": {
        "id": "t7LNX3IQCMb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = modified_vgg19_model.evaluate(X_test, Y_test)\n",
        "print(f'Test Accuracy': {test_acc * 100:2f}%)"
      ],
      "metadata": {
        "id": "x-PMbM_zCaNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizin Predictions with a confusion Mattrix for Modified VGG19**"
      ],
      "metadata": {
        "id": "FHSyNMyaCr0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(model, X_test, Y_test, categories, title):\n",
        "  Y_pred = model.predict(X_test)\n",
        "  Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "  cm = confusion_matrix(Y_test, Y_pred_classes)\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('True')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(model=modified_vgg19_model, X_test=X_test, Y_test=Y_test, categories=categories, title='Modified VGG19')"
      ],
      "metadata": {
        "id": "79_-kVKCDC1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating The Calssification Report for MOdified VGG19**"
      ],
      "metadata": {
        "id": "Kpws0_i4Dyq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = modified_vgg19_model.predict(X_test)\n",
        "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "#Print the Classifocation Report\n",
        "print(classification_report(Y_test, Y_pred_classes, target_names=categories))\n",
        "#"
      ],
      "metadata": {
        "id": "3wvafaZKEHDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install the Efficient Library**"
      ],
      "metadata": {
        "id": "lQhV9StzEQxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q efficient"
      ],
      "metadata": {
        "id": "JIq6lNSqElJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building and Compiling a cuistomized EfficientNETB4 Model**"
      ],
      "metadata": {
        "id": "iCcAWvjMEyDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import efficientnet.tfkeras as efn\n",
        "\n",
        "enet = efn.EfficientNETB4(\n",
        "input_shape = input_shape,\n",
        "weights='imagenet'\n",
        "include_top=False\n",
        ")\n",
        "\n",
        "x = enet.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "e_model_b4 = tf.keras.models.Model(inputs=enet.input, output=y)\n",
        "e_model_b4.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(Learning_rate=5e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "e_model_b4.summary()"
      ],
      "metadata": {
        "id": "zpdWWIpTFBnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Part-of this Project**"
      ],
      "metadata": {
        "id": "cEQ5tTGnYHFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the EfficientNETB4 Model**"
      ],
      "metadata": {
        "id": "yKVIf7j-YN-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficient_b4 = e_model_b4.fit(x=X_train, y=Y_train, epochs=10, validation_data=(X_test, Y_test), batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "collapsed": true,
        "id": "rkAUrXEUYfzK",
        "outputId": "f9bf0d25-a845-45fe-9ed8-092b60b41f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'e_model_b4' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2677803390.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mefficient_b4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_model_b4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'e_model_b4' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize Model Performance - Accuracy & Loss Curves**"
      ],
      "metadata": {
        "id": "BNJtoK78ZhYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, title):\n",
        "  plt.figure(figsize=(12, 4))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.title(f'{title} - Accuracy Curves')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(history.history['loss'], label='train loss')\n",
        "  plt.plot(history.history['val_loss'], label='val loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.title(f'{title} - Loss Curves')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  plot_history(history=efficient_b4, title='EfficientNetB4')"
      ],
      "metadata": {
        "id": "T-EN_hDOZsQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss, valid_acc = e_model_b4.evaluate(X_test, Y_test)\n",
        "train_loss, train_acc = e_model_b4.evaluate(X_train, Y_train)\n",
        "print(f'\\nValidation Accuracy: {valid_acc}')\n",
        "print(f'\\nValidation Loss: {valid_loss}')\n",
        "print(f'\\nTraining Accuracy: {train_acc}')\n",
        "print(f'\\nTraining Loss: {train_loss}')"
      ],
      "metadata": {
        "id": "L_0FaAbNantj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Model Evaluation on Test Data**"
      ],
      "metadata": {
        "id": "lN4mqrLKagm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = e_model_b4.evaluate(X_test, Y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:2f}%')"
      ],
      "metadata": {
        "id": "UJfIvsnYa_5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving the Trained EfficientNETB4 Model**"
      ],
      "metadata": {
        "id": "lPzam1T6bJ8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model\n",
        "e_model_b4.save('/content/drive/MyDrive/new_projects/p5/e_model_b4.h5')"
      ],
      "metadata": {
        "id": "hEdp6bP7bXfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot EfficientNETB4 Confusion Matrix**"
      ],
      "metadata": {
        "id": "9vT2q2xzbod1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(model, X_test, Y_test, categories, title):\n",
        "  Y_pred = model.predict(X_test)\n",
        "  Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "  cm = confusion_matrix(Y_test, Y_pred_classes)\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('True')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(model=e_model_b4, X_test=X_test, Y_test=Y_test, categories=categories, title='EfficientNetB4')"
      ],
      "metadata": {
        "id": "6a2NoOlRb0-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = e_model_b4.predict(X_test)\n",
        "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print('\\n EfficientNETB4 Classification Report:')\n",
        "print(classification_report(Y_test, Y_pred_classes, target_names=categories))"
      ],
      "metadata": {
        "id": "3nTWwM_ocSGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lead Custom VGG19 Model with FixedDropout**"
      ],
      "metadata": {
        "id": "vWEpX8ykcBjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-applications\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dropout\n",
        "\n",
        "Class FixedDropout(Dropout):\n",
        "def _get_noise_shape(shape, input):\n",
        "  If self.noise_shape is None:\n",
        "     return self.noise_shape\n",
        "\n",
        "  symbolic_shape = tf.keras.backend.shape(input)\n",
        "  noise_shape = [symbolic_shape[axis] if shape[axis] is None else shape[axis] for axis in range(symbolic_shape.shape[0])]\n",
        "  return tuple(noise_shape)\n",
        "\n",
        "with tf.keras.utils.custom_object_scope({'FixedDropout': FixedDropout}):\n",
        "  loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/new_projects/p5/modified_vgg19_custom_model.h5')"
      ],
      "metadata": {
        "id": "tHkotGCudQPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict and Visualize a single Leaf Image **"
      ],
      "metadata": {
        "id": "aS-pdXELe3xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = cv2.imread(\"/content/drive/MyDrive/new_projects/p5/Leaf_Disease_Detection/Validation/Apple__healthy/04125537__801d-4e15-b66c-224b09b4e1a7__RS_HL 7457.JPG\")# Replace with your path\n",
        "img_resized = cv2.resize(img_array, (img_size, img_size))\n",
        "img_normalized = img_resized / 255.0\n",
        "img_array = np.expand_dims(img_normalized, axis=0)\n",
        "\n",
        "prediction = loaded_model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction)\n",
        "predicted_class = categories[predicted_class]\n",
        "\n",
        "plt.imshow(img_array[0])\n",
        "plt.title(f'Predicted Class: {predicted_class}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ppPAkW8BfFAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict and Display a Raspberry Leaf Image**"
      ],
      "metadata": {
        "id": "n_kZSsbjhUm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = cv2.imread(\"/content/drive/MyDrive/new_projects/p5/Leaf_Disease_Detection/Validation/Raspberry__healthy/05dfc382__396a-4301-b948-7d1098feba11__Mary_HL 6358.JPG\")# Replace with your path\n",
        "img_resized = cv2.resize(img_array, (img_size, img_size))\n",
        "img_normalized = img_resized / 255.0\n",
        "img_array = np.expand_dims(img_normalized, axis=0)\n",
        "\n",
        "prediction = loaded_model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction)\n",
        "predicted_class = categories[predicted_class]\n",
        "\n",
        "plt.imshow(img_array[0])\n",
        "plt.title(f'Predicted Class: {predicted_class}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6_yh_d2Dhi8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally the project is completed and i got my results:"
      ],
      "metadata": {
        "id": "OpD2lOcRkPX_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}